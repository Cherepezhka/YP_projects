{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#SVC\" data-toc-modified-id=\"SVC-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>SVC</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>SGDClassifier</a></span></li><li><span><a href=\"#LGBM\" data-toc-modified-id=\"LGBM-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>LGBM</a></span></li><li><span><a href=\"#FastText\" data-toc-modified-id=\"FastText-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>FastText</a></span></li><li><span><a href=\"#Результаты-работы-моделей\" data-toc-modified-id=\"Результаты-работы-моделей-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Результаты работы моделей</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Тестирование</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "#import torch              \n",
    "#import transformers      \n",
    "from tqdm import notebook\n",
    "\n",
    "from time import perf_counter\n",
    "import optuna\n",
    "from optuna.integration import OptunaSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import fasttext\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Oleg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Oleg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Oleg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соотношение классов в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    0.898388\n",
       "1    0.101612\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts(subset='toxic',normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция очистки текста от ненужных символов, пунктуации и чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = (text.str.lower() \\\n",
    "             .str.replace(r'[^\\sa-zA-Z0-9@\\[\\]]',  ' ', regex = True) \\\n",
    "             .str.replace(r'\\n', ' ') \\\n",
    "             .str.replace(r'\\w*\\d+\\w*',  '', regex = True) \\\n",
    "             .str.replace('\\s{2,}',  \" \", regex = True))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для лемманизации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    text = text.apply(nltk.word_tokenize)\n",
    "    return text.apply(lambda tokens: \" \".join([wnl.lemmatize(token) for token in tokens])) #if token not in stopw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгрузим стоп слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(nltk_stopwords.words('english')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функции очистки и лемманизации слов текста. Сохраним в отдельный столбец датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['preprocessed_text'] = clean_text(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['preprocessed_text'] = lemmatize(data['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* Рассмотрен датасет комментариев в интернет-магазине с разметкой о токсичности правок.\n",
    "* Проведена очистка текста от ненужных символов, пунктуации и чисел.\n",
    "* Проведена лемманизация слов в тексте"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline:**\n",
    "\n",
    "* Text Cleaner\n",
    "* Text Lemma\n",
    "* TF IDF\n",
    "* Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['preprocessed_text']\n",
    "target = data['toxic']\n",
    "\n",
    "features_split, features_test, target_split, target_test = train_test_split(features, target, test_size=0.2)\n",
    "features_train, features_val, target_train, target_val = train_test_split(features_split, target_split, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для сбора результатов работы моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelResults(model_search, model_name, results):\n",
    "    \n",
    "    model = model_search.best_estimator_\n",
    "    \n",
    "    #Определим время fit модели \n",
    "    t_start_1 = perf_counter()\n",
    "    model.fit(features_train, target_train)\n",
    "    t_stop_1 = perf_counter()\n",
    "\n",
    "    #Определим время predict модели \n",
    "    t_start_2 = perf_counter()\n",
    "    p_val = model.predict(features_val)\n",
    "    t_stop_2 = perf_counter()\n",
    "\n",
    "    results[model_name] = [abs(model_search.best_score_), f1_score(target_val, p_val),t_stop_1 - t_start_1, t_stop_2 - t_start_2]\n",
    "\n",
    "    #pd.DataFrame(model.feature_importances_, \n",
    "                       #index = features_train.columns, \n",
    "                       #columns =['Importance']).sort_values(by='Importance').plot(kind='barh', figsize = (18,6), title ='Feature Importances')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададимся random state\n",
    "RANDOM_STATE = 808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим StratifiedKFold для разбиение на стратифицированные выборки при кросс-валидации\n",
    "skf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для результатов работы рассматриваемых моделей\n",
    "results = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 22:45:44,004]\u001b[0m A new study created in memory with name: no-name-29249a4d-6960-4017-89ed-0e90718c1abc\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:51,632]\u001b[0m Trial 13 finished with value: 0.7548167436445516 and parameters: {'model__solver': 'liblinear', 'model__C': 10.123047987693825}. Best is trial 13 with value: 0.7548167436445516.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:51,959]\u001b[0m Trial 5 finished with value: 0.7239794981226519 and parameters: {'model__solver': 'saga', 'model__C': 14.968471445797686}. Best is trial 13 with value: 0.7548167436445516.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:52,551]\u001b[0m Trial 6 finished with value: 0.7549941561779145 and parameters: {'model__solver': 'liblinear', 'model__C': 4.2520385611107345}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:53,427]\u001b[0m Trial 4 finished with value: 0.751916468814164 and parameters: {'model__solver': 'liblinear', 'model__C': 1.929370973226722}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:53,642]\u001b[0m Trial 14 finished with value: 0.7515953376179271 and parameters: {'model__solver': 'liblinear', 'model__C': 17.144661048559033}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:54,081]\u001b[0m Trial 12 finished with value: 0.734797092903151 and parameters: {'model__solver': 'saga', 'model__C': 77.03597761697577}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:54,367]\u001b[0m Trial 8 finished with value: 0.7336166880010283 and parameters: {'model__solver': 'saga', 'model__C': 91.84977053088093}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:54,623]\u001b[0m Trial 7 finished with value: 0.7314861775353649 and parameters: {'model__solver': 'saga', 'model__C': 16.56634836660136}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:55,064]\u001b[0m Trial 11 finished with value: 0.714357401504392 and parameters: {'model__solver': 'saga', 'model__C': 9.013495853409594}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:55,350]\u001b[0m Trial 1 finished with value: 0.7356853501194366 and parameters: {'model__solver': 'saga', 'model__C': 22.94105720177193}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:56,487]\u001b[0m Trial 0 finished with value: 0.744840012933781 and parameters: {'model__solver': 'saga', 'model__C': 38.285128590052196}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:56,683]\u001b[0m Trial 9 finished with value: 0.7518495266213238 and parameters: {'model__solver': 'liblinear', 'model__C': 17.797576216787746}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:48:56,777]\u001b[0m Trial 15 finished with value: 0.7451994003542736 and parameters: {'model__solver': 'saga', 'model__C': 1.0717041138944396}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:49:05,335]\u001b[0m Trial 2 finished with value: 0.7401178382436188 and parameters: {'model__solver': 'saga', 'model__C': 43.52947999714938}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:49:05,671]\u001b[0m Trial 10 finished with value: 0.7425867907155337 and parameters: {'model__solver': 'saga', 'model__C': 41.41881981394527}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:49:22,954]\u001b[0m Trial 3 finished with value: 0.7458175639424217 and parameters: {'model__solver': 'saga', 'model__C': 3.0685184015802354}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,108]\u001b[0m Trial 22 finished with value: 0.7467775727110525 and parameters: {'model__solver': 'liblinear', 'model__C': 33.68839175563357}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,211]\u001b[0m Trial 19 finished with value: 0.7448376165886863 and parameters: {'model__solver': 'liblinear', 'model__C': 42.61903329418494}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,238]\u001b[0m Trial 25 finished with value: 0.7548954958873866 and parameters: {'model__solver': 'liblinear', 'model__C': 5.783836269057746}. Best is trial 6 with value: 0.7549941561779145.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,258]\u001b[0m Trial 20 finished with value: 0.7552807581329578 and parameters: {'model__solver': 'liblinear', 'model__C': 3.86118028990922}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,279]\u001b[0m Trial 26 finished with value: 0.7547697191951611 and parameters: {'model__solver': 'liblinear', 'model__C': 5.978659637853799}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,298]\u001b[0m Trial 23 finished with value: 0.7458230577064214 and parameters: {'model__solver': 'liblinear', 'model__C': 1.198258973923741}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,320]\u001b[0m Trial 17 finished with value: 0.7368672925192095 and parameters: {'model__solver': 'saga', 'model__C': 38.437469055039486}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,342]\u001b[0m Trial 24 finished with value: 0.7450632039185755 and parameters: {'model__solver': 'liblinear', 'model__C': 1.0897945089274113}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:26,393]\u001b[0m Trial 27 finished with value: 0.7550421455321114 and parameters: {'model__solver': 'liblinear', 'model__C': 5.585828143532973}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:33,479]\u001b[0m Trial 28 finished with value: 0.7549103169251113 and parameters: {'model__solver': 'liblinear', 'model__C': 5.356543935151017}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:33,487]\u001b[0m Trial 29 finished with value: 0.7548597168079331 and parameters: {'model__solver': 'liblinear', 'model__C': 5.777580428409244}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:33,500]\u001b[0m Trial 21 finished with value: 0.745150219520319 and parameters: {'model__solver': 'saga', 'model__C': 14.908660145805737}. Best is trial 20 with value: 0.7552807581329578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:33,527]\u001b[0m Trial 16 finished with value: 0.760681151035238 and parameters: {'model__solver': 'saga', 'model__C': 4.013898901379134}. Best is trial 16 with value: 0.760681151035238.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:51:33,554]\u001b[0m Trial 18 finished with value: 0.7346219529387757 and parameters: {'model__solver': 'saga', 'model__C': 84.04453169341203}. Best is trial 16 with value: 0.760681151035238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Лучшие параметры: {'model__solver': 'saga', 'model__C': 4.013898901379134}\n",
      "F1 на тренировочной выборке: 0.760681151035238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=4.013898901379134,\n",
       "                                    class_weight=&#x27;balanced&#x27;, random_state=808,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=4.013898901379134,\n",
       "                                    class_weight=&#x27;balanced&#x27;, random_state=808,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;, &#x27;yours&#x27;, &#x27;wasn&#x27;,\n",
       "                            &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;, &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                            &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;, &#x27;an&#x27;, &#x27;those&#x27;,\n",
       "                            &#x27;until&#x27;, &#x27;than&#x27;, &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                            &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;, &quot;won&#x27;t&quot;, ...],\n",
       "                sublinear_tf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.013898901379134, class_weight=&#x27;balanced&#x27;,\n",
       "                   random_state=808, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[\"that'll\", 'him', 'up', 'again',\n",
       "                                             'yours', 'wasn', 've', 'a', 'each',\n",
       "                                             'their', \"you'd\", 'her', 'then',\n",
       "                                             'wouldn', 'we', 'don', 'will',\n",
       "                                             'an', 'those', 'until', 'than',\n",
       "                                             'too', 'some', 'your', 'on',\n",
       "                                             'such', 'ma', 'mustn', 'himself',\n",
       "                                             \"won't\", ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=4.013898901379134,\n",
       "                                    class_weight='balanced', random_state=808,\n",
       "                                    solver='saga'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_pipe = Pipeline([('tfidf', TfidfVectorizer(min_df=2, max_df=0.8, stop_words=stopwords, sublinear_tf=True)), \n",
    "                     ('model', LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "\n",
    "parameters = {'model__solver': optuna.distributions.CategoricalDistribution(['liblinear', 'saga']),\n",
    "                'model__C': optuna.distributions.FloatDistribution(1, 100, log=True)}\n",
    "\n",
    "\n",
    "optuna_search_log = OptunaSearchCV(log_pipe, parameters, n_trials=30, cv=skf, n_jobs=-1, scoring='f1', random_state=RANDOM_STATE) \n",
    "optuna_search_log.fit(features_train, target_train)\n",
    "\n",
    "print('\\n')\n",
    "print(f'Лучшие параметры: {optuna_search_log.best_params_}')\n",
    "print(f'F1 на тренировочной выборке: {abs(optuna_search_log.best_score_)}')\n",
    "display(optuna_search_log.best_estimator_)\n",
    "ModelResults(optuna_search_log, 'LogisticRegression', results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 22:51:51,768]\u001b[0m A new study created in memory with name: no-name-60a3d16e-452c-469a-847c-b82d5bbd75f4\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:47,970]\u001b[0m Trial 8 finished with value: 0.7515209040308871 and parameters: {'model__C': 0.5920017077468036}. Best is trial 8 with value: 0.7515209040308871.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:57,896]\u001b[0m Trial 0 finished with value: 0.7291566206103535 and parameters: {'model__C': 4.883136219603911}. Best is trial 8 with value: 0.7515209040308871.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:57,960]\u001b[0m Trial 2 finished with value: 0.7425658439908126 and parameters: {'model__C': 1.713654062491799}. Best is trial 8 with value: 0.7515209040308871.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,232]\u001b[0m Trial 9 finished with value: 0.7533332540733149 and parameters: {'model__C': 0.3869715658277677}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,499]\u001b[0m Trial 14 finished with value: 0.7438038845911529 and parameters: {'model__C': 1.5785747188059918}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,640]\u001b[0m Trial 1 finished with value: 0.7497821698441408 and parameters: {'model__C': 0.819546649403085}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,763]\u001b[0m Trial 11 finished with value: 0.7159669085970525 and parameters: {'model__C': 10.967090730329842}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,810]\u001b[0m Trial 12 finished with value: 0.7332370621032845 and parameters: {'model__C': 3.68207322139611}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,816]\u001b[0m Trial 3 finished with value: 0.6951644843058168 and parameters: {'model__C': 33.152847154008505}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,844]\u001b[0m Trial 10 finished with value: 0.7355566887765699 and parameters: {'model__C': 3.1655542505596155}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:58,922]\u001b[0m Trial 15 finished with value: 0.7238930004878643 and parameters: {'model__C': 6.713710237531524}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:59,130]\u001b[0m Trial 6 finished with value: 0.6772353534462926 and parameters: {'model__C': 84.97630400661691}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:59,196]\u001b[0m Trial 4 finished with value: 0.7280564648417105 and parameters: {'model__C': 5.32341849702724}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:54:59,210]\u001b[0m Trial 13 finished with value: 0.7338627134958791 and parameters: {'model__C': 3.5326009541146375}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:55:00,278]\u001b[0m Trial 7 finished with value: 0.7218684093303828 and parameters: {'model__C': 7.868097794142085}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:55:25,271]\u001b[0m Trial 5 finished with value: 0.6904303560907873 and parameters: {'model__C': 42.58938056058812}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:36,128]\u001b[0m Trial 16 finished with value: 0.7133390795725868 and parameters: {'model__C': 12.61520633692962}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:53,421]\u001b[0m Trial 25 finished with value: 0.7521253374550106 and parameters: {'model__C': 0.18283526502030387}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:55,021]\u001b[0m Trial 23 finished with value: 0.751818252368706 and parameters: {'model__C': 0.1921731154844261}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:55,176]\u001b[0m Trial 22 finished with value: 0.7516136796840075 and parameters: {'model__C': 0.19772396565641417}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:56,323]\u001b[0m Trial 24 finished with value: 0.751818252368706 and parameters: {'model__C': 0.19219588110380897}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:56,703]\u001b[0m Trial 28 finished with value: 0.7510000604351404 and parameters: {'model__C': 0.1598936623697292}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:56,735]\u001b[0m Trial 17 finished with value: 0.6762292586878713 and parameters: {'model__C': 92.38416675016737}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:58,493]\u001b[0m Trial 30 finished with value: 0.7512798559523249 and parameters: {'model__C': 0.21174524011234444}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:58,713]\u001b[0m Trial 19 finished with value: 0.7531293541081795 and parameters: {'model__C': 0.4752610089506803}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:57:59,486]\u001b[0m Trial 21 finished with value: 0.7499842711616411 and parameters: {'model__C': 0.12625033851404005}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:58:00,371]\u001b[0m Trial 18 finished with value: 0.7134776760476121 and parameters: {'model__C': 12.557660080919668}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:58:01,147]\u001b[0m Trial 27 finished with value: 0.7514621482964099 and parameters: {'model__C': 0.19392205354542408}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:58:01,631]\u001b[0m Trial 20 finished with value: 0.7437572250404281 and parameters: {'model__C': 1.5658095550576425}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:58:06,069]\u001b[0m Trial 26 finished with value: 0.7511997056503232 and parameters: {'model__C': 0.207108028437463}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:58:11,778]\u001b[0m Trial 29 finished with value: 0.7511837566223655 and parameters: {'model__C': 0.16484983204258014}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 22:58:22,028]\u001b[0m Trial 31 finished with value: 0.7511545112241585 and parameters: {'model__C': 0.21819960885119521}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:24,143]\u001b[0m Trial 32 finished with value: 0.7505057763720946 and parameters: {'model__C': 0.13262453617860634}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:36,276]\u001b[0m Trial 34 finished with value: 0.749333305337868 and parameters: {'model__C': 0.11885586306605117}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:39,041]\u001b[0m Trial 37 finished with value: 0.74711911199408 and parameters: {'model__C': 0.10212886543661556}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:41,040]\u001b[0m Trial 33 finished with value: 0.7503016000877162 and parameters: {'model__C': 0.1312551396375049}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:41,774]\u001b[0m Trial 36 finished with value: 0.7470624342118081 and parameters: {'model__C': 0.1017825023482129}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:42,026]\u001b[0m Trial 38 finished with value: 0.7483634076227927 and parameters: {'model__C': 0.11142916037976248}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:44,500]\u001b[0m Trial 35 finished with value: 0.7503368601146584 and parameters: {'model__C': 0.12821041757053814}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:44,981]\u001b[0m Trial 39 finished with value: 0.7470046631715302 and parameters: {'model__C': 0.1026109531386167}. Best is trial 9 with value: 0.7533332540733149.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:58,044]\u001b[0m Trial 41 finished with value: 0.7533791359563802 and parameters: {'model__C': 0.37759549639010176}. Best is trial 41 with value: 0.7533791359563802.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:58,049]\u001b[0m Trial 42 finished with value: 0.7535170756315529 and parameters: {'model__C': 0.37372982241658687}. Best is trial 42 with value: 0.7535170756315529.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:58,676]\u001b[0m Trial 43 finished with value: 0.7532399846958886 and parameters: {'model__C': 0.37973207286472077}. Best is trial 42 with value: 0.7535170756315529.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:58,816]\u001b[0m Trial 40 finished with value: 0.7535287685727757 and parameters: {'model__C': 0.37165475819196864}. Best is trial 40 with value: 0.7535287685727757.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:00:59,773]\u001b[0m Trial 44 finished with value: 0.7535397851837288 and parameters: {'model__C': 0.35911738488222683}. Best is trial 44 with value: 0.7535397851837288.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:01:00,120]\u001b[0m Trial 46 finished with value: 0.7530092523500155 and parameters: {'model__C': 0.3275491421096348}. Best is trial 44 with value: 0.7535397851837288.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:01:00,128]\u001b[0m Trial 45 finished with value: 0.7533085540005767 and parameters: {'model__C': 0.4005192443368792}. Best is trial 44 with value: 0.7535397851837288.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:01:01,620]\u001b[0m Trial 47 finished with value: 0.7532398346872204 and parameters: {'model__C': 0.3909578877576026}. Best is trial 44 with value: 0.7535397851837288.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:01:13,297]\u001b[0m Trial 48 finished with value: 0.753366646866771 and parameters: {'model__C': 0.37639124324528955}. Best is trial 44 with value: 0.7535397851837288.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:01:14,811]\u001b[0m Trial 49 finished with value: 0.7530068027413748 and parameters: {'model__C': 0.382380575609312}. Best is trial 44 with value: 0.7535397851837288.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Лучшие параметры: {'model__C': 0.35911738488222683}\n",
      "F1 на тренировочной выборке: 0.7535397851837288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LinearSVC(C=0.35911738488222683, class_weight=&#x27;balanced&#x27;,\n",
       "                           random_state=808))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LinearSVC(C=0.35911738488222683, class_weight=&#x27;balanced&#x27;,\n",
       "                           random_state=808))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;, &#x27;yours&#x27;, &#x27;wasn&#x27;,\n",
       "                            &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;, &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                            &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;, &#x27;an&#x27;, &#x27;those&#x27;,\n",
       "                            &#x27;until&#x27;, &#x27;than&#x27;, &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                            &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;, &quot;won&#x27;t&quot;, ...],\n",
       "                sublinear_tf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=0.35911738488222683, class_weight=&#x27;balanced&#x27;, random_state=808)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[\"that'll\", 'him', 'up', 'again',\n",
       "                                             'yours', 'wasn', 've', 'a', 'each',\n",
       "                                             'their', \"you'd\", 'her', 'then',\n",
       "                                             'wouldn', 'we', 'don', 'will',\n",
       "                                             'an', 'those', 'until', 'than',\n",
       "                                             'too', 'some', 'your', 'on',\n",
       "                                             'such', 'ma', 'mustn', 'himself',\n",
       "                                             \"won't\", ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                ('model',\n",
       "                 LinearSVC(C=0.35911738488222683, class_weight='balanced',\n",
       "                           random_state=808))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svc_pipe =  Pipeline([('tfidf', TfidfVectorizer(min_df=2, max_df=0.8, stop_words=stopwords, sublinear_tf=True)), \n",
    "                     ('model', LinearSVC(class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "\n",
    "parameters = {'model__C': optuna.distributions.FloatDistribution(0.1, 100, log=True)}\n",
    "\n",
    "optuna_search_svc = OptunaSearchCV(svc_pipe, parameters, n_trials=50, cv=skf, n_jobs=-1, scoring='f1', random_state=RANDOM_STATE) \n",
    "optuna_search_svc.fit(features_train, target_train)\n",
    "\n",
    "print('\\n')\n",
    "print(f'Лучшие параметры: {optuna_search_svc.best_params_}')\n",
    "print(f'F1 на тренировочной выборке: {abs(optuna_search_svc.best_score_)}')\n",
    "display(optuna_search_svc.best_estimator_)\n",
    "ModelResults(optuna_search_svc, 'SVC', results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 23:01:24,848]\u001b[0m A new study created in memory with name: no-name-e990d928-ef48-4294-80fc-d9314ee46724\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:20,573]\u001b[0m Trial 11 finished with value: 0.6995575095029053 and parameters: {'model__penalty': 'l2', 'model__loss': 'perceptron', 'model__learning_rate': 'optimal'}. Best is trial 11 with value: 0.6995575095029053.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:20,684]\u001b[0m Trial 14 finished with value: 0.6267971509543214 and parameters: {'model__penalty': 'l1', 'model__loss': 'perceptron', 'model__learning_rate': 'optimal'}. Best is trial 11 with value: 0.6995575095029053.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:21,144]\u001b[0m Trial 15 finished with value: 0.6971203833440199 and parameters: {'model__penalty': 'l1', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 11 with value: 0.6995575095029053.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:21,191]\u001b[0m Trial 6 finished with value: 0.6971203833440199 and parameters: {'model__penalty': 'l1', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 11 with value: 0.6995575095029053.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:21,290]\u001b[0m Trial 2 finished with value: 0.6267971509543214 and parameters: {'model__penalty': 'l1', 'model__loss': 'perceptron', 'model__learning_rate': 'optimal'}. Best is trial 11 with value: 0.6995575095029053.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:21,433]\u001b[0m Trial 3 finished with value: 0.7064804977794769 and parameters: {'model__penalty': 'l2', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 3 with value: 0.7064804977794769.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:22,027]\u001b[0m Trial 10 finished with value: 0.6267971509543214 and parameters: {'model__penalty': 'l1', 'model__loss': 'perceptron', 'model__learning_rate': 'optimal'}. Best is trial 3 with value: 0.7064804977794769.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:22,968]\u001b[0m Trial 7 finished with value: 0.6971203833440199 and parameters: {'model__penalty': 'l1', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 3 with value: 0.7064804977794769.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:23,986]\u001b[0m Trial 1 finished with value: 0.7064804977794769 and parameters: {'model__penalty': 'l2', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 3 with value: 0.7064804977794769.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:24,147]\u001b[0m Trial 5 finished with value: 0.6971203833440199 and parameters: {'model__penalty': 'l1', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 3 with value: 0.7064804977794769.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:28,558]\u001b[0m Trial 8 finished with value: 0.7064804977794769 and parameters: {'model__penalty': 'l2', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 3 with value: 0.7064804977794769.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:30,261]\u001b[0m Trial 13 finished with value: 0.6971203833440199 and parameters: {'model__penalty': 'l1', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 3 with value: 0.7064804977794769.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:42,931]\u001b[0m Trial 4 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:48,131]\u001b[0m Trial 0 finished with value: 0.6971203833440199 and parameters: {'model__penalty': 'l1', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:54,239]\u001b[0m Trial 12 finished with value: 0.6267971509543214 and parameters: {'model__penalty': 'l1', 'model__loss': 'perceptron', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:04:54,512]\u001b[0m Trial 9 finished with value: 0.6576939257803393 and parameters: {'model__penalty': 'l1', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:06:58,427]\u001b[0m Trial 19 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:06:59,907]\u001b[0m Trial 18 finished with value: 0.6267971509543214 and parameters: {'model__penalty': 'l1', 'model__loss': 'perceptron', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:03,904]\u001b[0m Trial 20 finished with value: 0.7064804977794769 and parameters: {'model__penalty': 'l2', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:04,014]\u001b[0m Trial 16 finished with value: 0.6267971509543214 and parameters: {'model__penalty': 'l1', 'model__loss': 'perceptron', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:05,045]\u001b[0m Trial 17 finished with value: 0.6971203833440199 and parameters: {'model__penalty': 'l1', 'model__loss': 'epsilon_insensitive', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:30,840]\u001b[0m Trial 21 finished with value: 0.6576939257803393 and parameters: {'model__penalty': 'l1', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:31,302]\u001b[0m Trial 23 finished with value: 0.6576939257803393 and parameters: {'model__penalty': 'l1', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:32,258]\u001b[0m Trial 22 finished with value: 0.6576939257803393 and parameters: {'model__penalty': 'l1', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:39,162]\u001b[0m Trial 26 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:40,623]\u001b[0m Trial 27 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:41,399]\u001b[0m Trial 24 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:53,109]\u001b[0m Trial 25 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:58,699]\u001b[0m Trial 29 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:07:59,052]\u001b[0m Trial 28 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:08:00,108]\u001b[0m Trial 31 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:08:08,667]\u001b[0m Trial 30 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:46,554]\u001b[0m Trial 32 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:47,676]\u001b[0m Trial 33 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:47,801]\u001b[0m Trial 35 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:51,392]\u001b[0m Trial 34 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:09:52,359]\u001b[0m Trial 36 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:09,265]\u001b[0m Trial 38 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:11,099]\u001b[0m Trial 37 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:11,355]\u001b[0m Trial 39 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:29,619]\u001b[0m Trial 42 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:32,119]\u001b[0m Trial 40 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:33,401]\u001b[0m Trial 44 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:34,188]\u001b[0m Trial 41 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:36,665]\u001b[0m Trial 43 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:40,284]\u001b[0m Trial 45 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:40,602]\u001b[0m Trial 46 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:40,620]\u001b[0m Trial 47 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:46,642]\u001b[0m Trial 48 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:10:47,997]\u001b[0m Trial 49 finished with value: 0.7482718710846098 and parameters: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}. Best is trial 4 with value: 0.7482718710846098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Лучшие параметры: {'model__penalty': 'l2', 'model__loss': 'modified_huber', 'model__learning_rate': 'optimal'}\n",
      "F1 на тренировочной выборке: 0.7482718710846098\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 SGDClassifier(class_weight=&#x27;balanced&#x27;, loss=&#x27;modified_huber&#x27;,\n",
       "                               random_state=808))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 SGDClassifier(class_weight=&#x27;balanced&#x27;, loss=&#x27;modified_huber&#x27;,\n",
       "                               random_state=808))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;, &#x27;yours&#x27;, &#x27;wasn&#x27;,\n",
       "                            &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;, &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                            &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;, &#x27;an&#x27;, &#x27;those&#x27;,\n",
       "                            &#x27;until&#x27;, &#x27;than&#x27;, &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                            &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;, &quot;won&#x27;t&quot;, ...],\n",
       "                sublinear_tf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(class_weight=&#x27;balanced&#x27;, loss=&#x27;modified_huber&#x27;, random_state=808)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[\"that'll\", 'him', 'up', 'again',\n",
       "                                             'yours', 'wasn', 've', 'a', 'each',\n",
       "                                             'their', \"you'd\", 'her', 'then',\n",
       "                                             'wouldn', 'we', 'don', 'will',\n",
       "                                             'an', 'those', 'until', 'than',\n",
       "                                             'too', 'some', 'your', 'on',\n",
       "                                             'such', 'ma', 'mustn', 'himself',\n",
       "                                             \"won't\", ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                ('model',\n",
       "                 SGDClassifier(class_weight='balanced', loss='modified_huber',\n",
       "                               random_state=808))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sgd_pipe =  Pipeline([('tfidf', TfidfVectorizer(min_df=2, max_df=0.8, stop_words=stopwords, sublinear_tf=True)), \n",
    "                     ('model', SGDClassifier(class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "\n",
    "\n",
    "parameters = {'model__penalty': optuna.distributions.CategoricalDistribution(['l1', 'l2']),\n",
    "             'model__loss': optuna.distributions.CategoricalDistribution(['modified_huber', 'perceptron', 'epsilon_insensitive']),\n",
    "             'model__learning_rate': optuna.distributions.CategoricalDistribution(['optimal'])} #, 'invscaling' ,'adaptive'\n",
    "\n",
    "\n",
    "\n",
    "optuna_search_sgd = OptunaSearchCV(sgd_pipe, parameters, n_trials=50, cv=skf, n_jobs=-1, scoring='f1', random_state=RANDOM_STATE) \n",
    "optuna_search_sgd.fit(features_train, target_train)\n",
    "\n",
    "print('\\n')\n",
    "print(f'Лучшие параметры: {optuna_search_sgd.best_params_}')\n",
    "print(f'F1 на тренировочной выборке: {abs(optuna_search_sgd.best_score_)}')\n",
    "display(optuna_search_sgd.best_estimator_)\n",
    "ModelResults(optuna_search_sgd, 'SGDClassifier', results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 23:10:57,601]\u001b[0m A new study created in memory with name: no-name-9a05de98-4779-43b2-877f-0a366cc258dc\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:19:19,465]\u001b[0m Trial 10 finished with value: 0.6387893109604591 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 300, 'model__learning_rate': 0.0048261995341648215, 'model__n_estimators': 100}. Best is trial 10 with value: 0.6387893109604591.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:20:46,340]\u001b[0m Trial 13 finished with value: 0.6860240697146369 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 200, 'model__learning_rate': 0.028008850815355972, 'model__n_estimators': 100}. Best is trial 13 with value: 0.6860240697146369.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:20:50,903]\u001b[0m Trial 1 finished with value: 0.6641492131494035 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 250, 'model__learning_rate': 0.03657345463929404, 'model__n_estimators': 100}. Best is trial 13 with value: 0.6860240697146369.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:20:56,434]\u001b[0m Trial 11 finished with value: 0.6618449045228637 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 250, 'model__learning_rate': 0.030127073825461283, 'model__n_estimators': 100}. Best is trial 13 with value: 0.6860240697146369.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:20:59,370]\u001b[0m Trial 12 finished with value: 0.6754342840432046 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 250, 'model__learning_rate': 0.049553055583850605, 'model__n_estimators': 100}. Best is trial 13 with value: 0.6860240697146369.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:21:41,320]\u001b[0m Trial 3 finished with value: 0.6789207565499024 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 200, 'model__learning_rate': 0.016816062023832706, 'model__n_estimators': 150}. Best is trial 13 with value: 0.6860240697146369.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:22:54,398]\u001b[0m Trial 8 finished with value: 0.6913990506224087 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 250, 'model__learning_rate': 0.04558416202625085, 'model__n_estimators': 150}. Best is trial 8 with value: 0.6913990506224087.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:22:54,602]\u001b[0m Trial 4 finished with value: 0.6519012831217341 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 200, 'model__learning_rate': 0.011654274841555196, 'model__n_estimators': 150}. Best is trial 8 with value: 0.6913990506224087.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:23:02,058]\u001b[0m Trial 15 finished with value: 0.6306648830713346 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 250, 'model__learning_rate': 0.0011586426663847233, 'model__n_estimators': 150}. Best is trial 8 with value: 0.6913990506224087.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:23:31,705]\u001b[0m Trial 14 finished with value: 0.7286935706815151 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 250, 'model__learning_rate': 0.04525979068178659, 'model__n_estimators': 200}. Best is trial 14 with value: 0.7286935706815151.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:23:57,826]\u001b[0m Trial 2 finished with value: 0.6658712946294935 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 100, 'model__learning_rate': 0.019127667817635086, 'model__n_estimators': 200}. Best is trial 14 with value: 0.7286935706815151.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:24:58,666]\u001b[0m Trial 5 finished with value: 0.6638519792105148 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 150, 'model__learning_rate': 0.017742049814629124, 'model__n_estimators': 200}. Best is trial 14 with value: 0.7286935706815151.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:25:16,948]\u001b[0m Trial 7 finished with value: 0.6421791571484491 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 300, 'model__learning_rate': 0.0013209707020402106, 'model__n_estimators': 250}. Best is trial 14 with value: 0.7286935706815151.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:25:41,165]\u001b[0m Trial 9 finished with value: 0.655527066148248 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 150, 'model__learning_rate': 0.011226212265244373, 'model__n_estimators': 250}. Best is trial 14 with value: 0.7286935706815151.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:26:20,275]\u001b[0m Trial 0 finished with value: 0.6344538390121267 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 250, 'model__learning_rate': 0.0014474881973825353, 'model__n_estimators': 300}. Best is trial 14 with value: 0.7286935706815151.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:26:20,656]\u001b[0m Trial 6 finished with value: 0.7305214915972643 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 300, 'model__learning_rate': 0.03208451343698744, 'model__n_estimators': 300}. Best is trial 6 with value: 0.7305214915972643.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:27:10,697]\u001b[0m Trial 18 finished with value: 0.6870920875451704 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 100, 'model__learning_rate': 0.04396976248822428, 'model__n_estimators': 150}. Best is trial 6 with value: 0.7305214915972643.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:27:39,955]\u001b[0m Trial 19 finished with value: 0.6427086808388656 and parameters: {'model__boosting_type': 'gbdt', 'model__max_depth': 250, 'model__learning_rate': 0.0017988467785202817, 'model__n_estimators': 200}. Best is trial 6 with value: 0.7305214915972643.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:27:40,079]\u001b[0m Trial 17 finished with value: 0.6689083530813985 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 300, 'model__learning_rate': 0.021120475640304268, 'model__n_estimators': 200}. Best is trial 6 with value: 0.7305214915972643.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 23:28:06,139]\u001b[0m Trial 16 finished with value: 0.7220784011941381 and parameters: {'model__boosting_type': 'dart', 'model__max_depth': 300, 'model__learning_rate': 0.06907810708923413, 'model__n_estimators': 300}. Best is trial 6 with value: 0.7305214915972643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Лучшие параметры: {'model__boosting_type': 'gbdt', 'model__max_depth': 300, 'model__learning_rate': 0.03208451343698744, 'model__n_estimators': 300}\n",
      "F1 на тренировочной выборке: 0.7305214915972643\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                learning_rate=0.03208451343698744,\n",
       "                                max_depth=300, n_estimators=300,\n",
       "                                random_state=808))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;,\n",
       "                                             &#x27;yours&#x27;, &#x27;wasn&#x27;, &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;,\n",
       "                                             &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                                             &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;,\n",
       "                                             &#x27;an&#x27;, &#x27;those&#x27;, &#x27;until&#x27;, &#x27;than&#x27;,\n",
       "                                             &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                                             &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;,\n",
       "                                             &quot;won&#x27;t&quot;, ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                learning_rate=0.03208451343698744,\n",
       "                                max_depth=300, n_estimators=300,\n",
       "                                random_state=808))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                stop_words=[&quot;that&#x27;ll&quot;, &#x27;him&#x27;, &#x27;up&#x27;, &#x27;again&#x27;, &#x27;yours&#x27;, &#x27;wasn&#x27;,\n",
       "                            &#x27;ve&#x27;, &#x27;a&#x27;, &#x27;each&#x27;, &#x27;their&#x27;, &quot;you&#x27;d&quot;, &#x27;her&#x27;, &#x27;then&#x27;,\n",
       "                            &#x27;wouldn&#x27;, &#x27;we&#x27;, &#x27;don&#x27;, &#x27;will&#x27;, &#x27;an&#x27;, &#x27;those&#x27;,\n",
       "                            &#x27;until&#x27;, &#x27;than&#x27;, &#x27;too&#x27;, &#x27;some&#x27;, &#x27;your&#x27;, &#x27;on&#x27;,\n",
       "                            &#x27;such&#x27;, &#x27;ma&#x27;, &#x27;mustn&#x27;, &#x27;himself&#x27;, &quot;won&#x27;t&quot;, ...],\n",
       "                sublinear_tf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, learning_rate=0.03208451343698744,\n",
       "               max_depth=300, n_estimators=300, random_state=808)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                 stop_words=[\"that'll\", 'him', 'up', 'again',\n",
       "                                             'yours', 'wasn', 've', 'a', 'each',\n",
       "                                             'their', \"you'd\", 'her', 'then',\n",
       "                                             'wouldn', 'we', 'don', 'will',\n",
       "                                             'an', 'those', 'until', 'than',\n",
       "                                             'too', 'some', 'your', 'on',\n",
       "                                             'such', 'ma', 'mustn', 'himself',\n",
       "                                             \"won't\", ...],\n",
       "                                 sublinear_tf=True)),\n",
       "                ('model',\n",
       "                 LGBMClassifier(class_weight='balanced',\n",
       "                                learning_rate=0.03208451343698744,\n",
       "                                max_depth=300, n_estimators=300,\n",
       "                                random_state=808))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_pipe =  Pipeline([('tfidf', TfidfVectorizer(min_df=2, max_df=0.8, stop_words=stopwords, sublinear_tf=True)), \n",
    "                     ('model', LGBMClassifier(class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "\n",
    "lgbm_params = {\n",
    "    'model__boosting_type' : optuna.distributions.CategoricalDistribution(['gbdt', 'dart']),\n",
    "    'model__max_depth': optuna.distributions.IntDistribution(100, 300, step=50),\n",
    "    'model__learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1, log=True),  \n",
    "    'model__n_estimators': optuna.distributions.IntDistribution(100, 300, step=50)\n",
    "}\n",
    "\n",
    "\n",
    "optuna_search_lgbm = OptunaSearchCV(lgbm_pipe, lgbm_params, n_trials=20, cv=skf, \n",
    "                                    n_jobs=-1, scoring='f1', random_state=RANDOM_STATE, timeout=600) \n",
    "optuna_search_lgbm.fit(features_train, target_train)\n",
    "\n",
    "#results['LightGBM'] = abs(optuna_search_lgbm.best_score_)\n",
    "\n",
    "print('\\n')\n",
    "print(f'Лучшие параметры: {optuna_search_lgbm.best_params_}')\n",
    "print(f'F1 на тренировочной выборке: {abs(optuna_search_lgbm.best_score_)}')\n",
    "display(optuna_search_lgbm.best_estimator_)\n",
    "ModelResults(optuna_search_lgbm, 'LightGBM', results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотекой FastText от исследовательской лаборатории искусственного интеллекта Facebook. В отличие от векторизации TF-IDF, она использует word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тренировочной выборке выборке: 0.9609309182813817\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = data.copy()\n",
    "\n",
    "# Очистим текст\n",
    "df['text'] = clean_text(df['text'])\n",
    "\n",
    "# Разобьем на тестовые и тренировочные данные\n",
    "splt, test = train_test_split(df[['toxic', 'text']], test_size=0.2)\n",
    "train, val = train_test_split(splt, test_size=0.25)\n",
    "\n",
    "# Сохраним целевой признак \n",
    "y_true_train = train['toxic']\n",
    "y_val_true = val['toxic']\n",
    "y_true_test = test['toxic']\n",
    "\n",
    "# Для обучения нужен файл, где целевой класс должен начинаться с __label__\n",
    "train['toxic'] = train['toxic'].apply(lambda x: '__label__' + str(x))\n",
    "\n",
    "train[['toxic', 'text']].to_csv('train_data.txt', header=False, index=False, sep=\"\\t\")\n",
    " \n",
    "# обучаем на 30 эпохах\n",
    "t_start_fit = perf_counter()\n",
    "model = fasttext.train_supervised(input='train_data.txt', epoch=30)\n",
    "t_stop_fit = perf_counter()\n",
    "\n",
    "# Predict на тренировочной выборке\n",
    "p_train = model.predict(train['text'].tolist(), k=1)\n",
    "\n",
    "# Валидационная выборка\n",
    "t_start_pred = perf_counter()\n",
    "p_val = model.predict(val['text'].tolist(), k=1)\n",
    "t_stop_pred = perf_counter()\n",
    "\n",
    "t_fit = t_stop_fit - t_start_fit\n",
    "t_pred = t_stop_pred - t_start_pred\n",
    "\n",
    "\n",
    "def p_unlabeled(p):\n",
    "    return [int(re.sub('__label__', '', val[0])) for val in p[0]]\n",
    "    \n",
    "#results['FastText'] = [None, f1_score(y_true_val, p_unlabeled(p_val)), t_fit, t_pred]  \n",
    "\n",
    "\n",
    "print(f'F1 на тренировочной выборке выборке: {f1_score(y_true_train, p_unlabeled(p_train))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидация для *FastText*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "sk = StratifiedKFold(n_splits=3)\n",
    "for train_idx, val_idx in sk.split(train['text'], train['toxic']): \n",
    "    X_train = train['text'].iloc[train_idx]\n",
    "    y_train = train['toxic'].iloc[train_idx]\n",
    "    \n",
    "    X_val = train['text'].iloc[val_idx]\n",
    "    y_val = train['toxic'].iloc[val_idx]\n",
    "    \n",
    "    pd.concat([y_train, X_train], axis=1).to_csv('Cross_val_data.txt', header=False, index=False, sep=\"\\t\")\n",
    "    \n",
    "    model_ft = fasttext.train_supervised(input='Cross_val_data.txt', epoch=30)\n",
    "\n",
    "    p = model_ft.predict(X_val.tolist(), k=1)\n",
    "    \n",
    "    p_labels_ = [int(re.sub('__label__', '', val[0])) for val in p[0]]\n",
    "    y_true_val = [int(re.sub('__label__', '', val)) for val in y_val]\n",
    "    \n",
    "    score = f1_score(y_true_val, p_labels_)\n",
    "    scores.append(score) \n",
    "cross_val_FT = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7741719638675143, 0.7772205144798576, 0.7709973753280841]\n",
      "0.7741299512251519\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(cross_val_FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['FastText'] = [cross_val_FT, f1_score(y_val_true, p_unlabeled(p_val)), t_fit, t_pred] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты работы моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81fd1_row0_col0, #T_81fd1_row0_col3, #T_81fd1_row1_col0, #T_81fd1_row1_col1, #T_81fd1_row1_col2, #T_81fd1_row1_col3, #T_81fd1_row3_col4 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81fd1_row0_col1, #T_81fd1_row0_col2 {\n",
       "  background-color: #fef6fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81fd1_row0_col4, #T_81fd1_row1_col4 {\n",
       "  background-color: #f9f2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81fd1_row2_col0, #T_81fd1_row2_col1, #T_81fd1_row2_col2, #T_81fd1_row2_col3, #T_81fd1_row2_col4 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_81fd1_row3_col0 {\n",
       "  background-color: #f7f0f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81fd1_row3_col1 {\n",
       "  background-color: #ede7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81fd1_row3_col2 {\n",
       "  background-color: #dddbec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81fd1_row3_col3 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81fd1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81fd1_level0_col0\" class=\"col_heading level0 col0\" >LogisticRegression</th>\n",
       "      <th id=\"T_81fd1_level0_col1\" class=\"col_heading level0 col1\" >SVC</th>\n",
       "      <th id=\"T_81fd1_level0_col2\" class=\"col_heading level0 col2\" >SGDClassifier</th>\n",
       "      <th id=\"T_81fd1_level0_col3\" class=\"col_heading level0 col3\" >LightGBM</th>\n",
       "      <th id=\"T_81fd1_level0_col4\" class=\"col_heading level0 col4\" >FastText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81fd1_level0_row0\" class=\"row_heading level0 row0\" >F1_cross_val</th>\n",
       "      <td id=\"T_81fd1_row0_col0\" class=\"data row0 col0\" >0.760681</td>\n",
       "      <td id=\"T_81fd1_row0_col1\" class=\"data row0 col1\" >0.753540</td>\n",
       "      <td id=\"T_81fd1_row0_col2\" class=\"data row0 col2\" >0.748272</td>\n",
       "      <td id=\"T_81fd1_row0_col3\" class=\"data row0 col3\" >0.730521</td>\n",
       "      <td id=\"T_81fd1_row0_col4\" class=\"data row0 col4\" >0.774130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fd1_level0_row1\" class=\"row_heading level0 row1\" >F1_Valid</th>\n",
       "      <td id=\"T_81fd1_row1_col0\" class=\"data row1 col0\" >0.734281</td>\n",
       "      <td id=\"T_81fd1_row1_col1\" class=\"data row1 col1\" >0.737784</td>\n",
       "      <td id=\"T_81fd1_row1_col2\" class=\"data row1 col2\" >0.727874</td>\n",
       "      <td id=\"T_81fd1_row1_col3\" class=\"data row1 col3\" >0.727908</td>\n",
       "      <td id=\"T_81fd1_row1_col4\" class=\"data row1 col4\" >0.785294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fd1_level0_row2\" class=\"row_heading level0 row2\" >Fit time,s</th>\n",
       "      <td id=\"T_81fd1_row2_col0\" class=\"data row2 col0\" >8.726652</td>\n",
       "      <td id=\"T_81fd1_row2_col1\" class=\"data row2 col1\" >4.389654</td>\n",
       "      <td id=\"T_81fd1_row2_col2\" class=\"data row2 col2\" >4.309867</td>\n",
       "      <td id=\"T_81fd1_row2_col3\" class=\"data row2 col3\" >32.943073</td>\n",
       "      <td id=\"T_81fd1_row2_col4\" class=\"data row2 col4\" >8.673178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fd1_level0_row3\" class=\"row_heading level0 row3\" >Prediction time,s</th>\n",
       "      <td id=\"T_81fd1_row3_col0\" class=\"data row3 col0\" >1.160367</td>\n",
       "      <td id=\"T_81fd1_row3_col1\" class=\"data row3 col1\" >1.188096</td>\n",
       "      <td id=\"T_81fd1_row3_col2\" class=\"data row3 col2\" >1.416336</td>\n",
       "      <td id=\"T_81fd1_row3_col3\" class=\"data row3 col3\" >1.285753</td>\n",
       "      <td id=\"T_81fd1_row3_col4\" class=\"data row3 col4\" >0.436117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b4293060a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results, index = ['F1_cross_val','F1_Valid', 'Fit time,s', 'Prediction time,s'], columns = results.keys() )\n",
    "res_df.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "sns.heatmap(res_df, annot=True, fmt = '.4f')\n",
    "plt.title('Полученные результаты для различных моделей')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* Библиотека FastText наилуший результат по метрике F1 на кросс-валидации и валидационной выборке."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.7881649354737174\n",
      "Wall time: 530 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = model.predict(test['text'].tolist(), k=1)\n",
    "    \n",
    "print(f'F1 на тестовой выборке: {f1_score(y_true_test, p_unlabeled(p))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Полученная метрика на тестовой выборке удовлетворяет условиям технического задания."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Рассмотрен датасет комментариев в интернет-магазине с разметкой о токсичности правок.Проведена очистка текста от ненужных символов, пунктуации, чисел и лемманизация слов в тексте.Создана матрица TF-IDF признаков.\n",
    "- Обучены модели для классификации комментариев на позитивные и негативные.\n",
    "- Рассмотрена библиотека FastText, использующая word embeddings.\n",
    "- FastText показала наилуший результат, удовлетворяющий условиям ТЗ по метрике F1."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 52,
    "start_time": "2023-02-12T14:59:16.841Z"
   },
   {
    "duration": 373,
    "start_time": "2023-02-12T14:59:18.952Z"
   },
   {
    "duration": 64,
    "start_time": "2023-02-12T14:59:20.436Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-12T14:59:28.807Z"
   },
   {
    "duration": 3305,
    "start_time": "2023-02-12T14:59:41.600Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-12T14:59:49.443Z"
   },
   {
    "duration": 34,
    "start_time": "2023-02-12T14:59:54.556Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-12T15:00:52.616Z"
   },
   {
    "duration": 522,
    "start_time": "2023-02-12T15:01:36.172Z"
   },
   {
    "duration": 45,
    "start_time": "2023-02-12T15:02:27.478Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-12T15:02:30.388Z"
   },
   {
    "duration": 346,
    "start_time": "2023-02-12T15:02:34.778Z"
   },
   {
    "duration": 729,
    "start_time": "2023-02-12T15:02:35.126Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-12T15:02:35.856Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-12T15:02:35.886Z"
   },
   {
    "duration": 358,
    "start_time": "2023-02-12T15:02:35.900Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-12T15:05:16.995Z"
   },
   {
    "duration": 109,
    "start_time": "2023-02-12T15:05:18.953Z"
   },
   {
    "duration": 133,
    "start_time": "2023-02-12T15:05:53.125Z"
   },
   {
    "duration": 112,
    "start_time": "2023-02-12T15:06:00.445Z"
   },
   {
    "duration": 115,
    "start_time": "2023-02-12T15:06:07.801Z"
   },
   {
    "duration": 162,
    "start_time": "2023-02-12T15:06:11.929Z"
   },
   {
    "duration": 102,
    "start_time": "2023-02-12T15:06:15.734Z"
   },
   {
    "duration": 884,
    "start_time": "2023-02-12T16:16:08.335Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-12T16:16:10.784Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-12T16:16:12.573Z"
   },
   {
    "duration": 4141,
    "start_time": "2023-02-14T14:15:49.661Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T14:16:01.668Z"
   },
   {
    "duration": 2662,
    "start_time": "2023-02-14T14:16:09.665Z"
   },
   {
    "duration": 41,
    "start_time": "2023-02-14T14:16:12.330Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T14:16:14.107Z"
   },
   {
    "duration": 736,
    "start_time": "2023-02-14T14:16:31.584Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T14:16:52.424Z"
   },
   {
    "duration": 279,
    "start_time": "2023-02-14T14:20:13.220Z"
   },
   {
    "duration": 1288,
    "start_time": "2023-02-15T09:31:49.619Z"
   },
   {
    "duration": 58,
    "start_time": "2023-02-16T08:34:54.491Z"
   },
   {
    "duration": 23213,
    "start_time": "2023-02-16T08:35:05.267Z"
   },
   {
    "duration": 1144,
    "start_time": "2023-02-16T08:35:41.525Z"
   },
   {
    "duration": 94,
    "start_time": "2023-02-16T08:36:56.931Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-16T08:37:03.002Z"
   },
   {
    "duration": 2079,
    "start_time": "2023-02-16T08:37:05.361Z"
   },
   {
    "duration": 3803,
    "start_time": "2023-02-16T08:37:09.772Z"
   },
   {
    "duration": 7483,
    "start_time": "2023-02-16T08:37:19.266Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-16T08:52:29.379Z"
   },
   {
    "duration": 79,
    "start_time": "2023-02-16T08:52:58.570Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T08:54:07.227Z"
   },
   {
    "duration": 208,
    "start_time": "2023-02-16T08:54:08.759Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T08:54:13.343Z"
   },
   {
    "duration": 206,
    "start_time": "2023-02-16T08:54:22.102Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-16T08:57:22.887Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T08:57:28.819Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-16T08:57:30.500Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T08:57:36.183Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-16T08:57:38.251Z"
   },
   {
    "duration": 209,
    "start_time": "2023-02-16T08:57:46.946Z"
   },
   {
    "duration": 9205,
    "start_time": "2023-02-16T09:07:52.903Z"
   },
   {
    "duration": 716,
    "start_time": "2023-02-16T09:55:41.945Z"
   },
   {
    "duration": 45,
    "start_time": "2023-02-16T10:17:38.139Z"
   },
   {
    "duration": 12273,
    "start_time": "2023-02-16T10:17:45.235Z"
   },
   {
    "duration": 39602,
    "start_time": "2023-02-16T10:19:27.109Z"
   },
   {
    "duration": 244,
    "start_time": "2023-02-16T10:24:30.736Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T10:24:56.535Z"
   },
   {
    "duration": 213,
    "start_time": "2023-02-16T10:24:58.343Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T10:25:41.324Z"
   },
   {
    "duration": 295,
    "start_time": "2023-02-16T10:25:42.934Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T10:26:40.741Z"
   },
   {
    "duration": 2933,
    "start_time": "2023-02-16T10:26:41.957Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T10:27:11.675Z"
   },
   {
    "duration": 15370,
    "start_time": "2023-02-16T10:27:13.253Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T10:27:38.752Z"
   },
   {
    "duration": 129,
    "start_time": "2023-02-16T10:28:18.537Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-16T10:28:34.391Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T10:28:42.253Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T10:28:51.663Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T10:29:27.844Z"
   },
   {
    "duration": 231,
    "start_time": "2023-02-16T10:29:31.944Z"
   },
   {
    "duration": 2500,
    "start_time": "2023-02-16T11:06:26.139Z"
   },
   {
    "duration": 1029,
    "start_time": "2023-02-16T11:06:28.641Z"
   },
   {
    "duration": 3109,
    "start_time": "2023-02-16T11:06:29.672Z"
   },
   {
    "duration": 1064,
    "start_time": "2023-02-16T11:06:32.783Z"
   },
   {
    "duration": 38,
    "start_time": "2023-02-16T11:06:33.852Z"
   },
   {
    "duration": 72,
    "start_time": "2023-02-16T11:06:33.892Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T11:06:33.966Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T11:06:33.976Z"
   },
   {
    "duration": 437,
    "start_time": "2023-02-16T11:06:33.981Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T11:06:34.431Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T11:06:34.432Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T11:06:34.432Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T11:06:44.483Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T11:26:55.728Z"
   },
   {
    "duration": 13995,
    "start_time": "2023-02-16T11:27:00.544Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T12:03:19.351Z"
   },
   {
    "duration": 14767,
    "start_time": "2023-02-16T12:03:20.764Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T12:05:22.156Z"
   },
   {
    "duration": 224,
    "start_time": "2023-02-16T12:06:10.162Z"
   },
   {
    "duration": 5012,
    "start_time": "2023-02-16T12:06:17.065Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-16T12:34:19.774Z"
   },
   {
    "duration": 15897,
    "start_time": "2023-02-16T12:34:21.250Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T12:35:33.892Z"
   },
   {
    "duration": 15318,
    "start_time": "2023-02-16T12:35:35.285Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T12:37:08.788Z"
   },
   {
    "duration": 441,
    "start_time": "2023-02-16T12:37:09.950Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-16T12:37:43.140Z"
   },
   {
    "duration": 15502,
    "start_time": "2023-02-16T12:37:45.056Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-16T12:46:39.265Z"
   },
   {
    "duration": 16519,
    "start_time": "2023-02-16T12:46:41.164Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T12:47:51.660Z"
   },
   {
    "duration": 15880,
    "start_time": "2023-02-16T12:47:53.436Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T12:48:21.532Z"
   },
   {
    "duration": 16325,
    "start_time": "2023-02-16T12:48:23.161Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-16T12:48:48.859Z"
   },
   {
    "duration": 16577,
    "start_time": "2023-02-16T12:48:52.298Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T12:50:32.301Z"
   },
   {
    "duration": 17875,
    "start_time": "2023-02-16T12:50:38.476Z"
   },
   {
    "duration": 13303,
    "start_time": "2023-02-16T13:01:36.393Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-16T13:07:47.840Z"
   },
   {
    "duration": 274,
    "start_time": "2023-02-16T13:36:18.929Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-16T13:37:03.672Z"
   },
   {
    "duration": 1784,
    "start_time": "2023-02-16T13:37:20.818Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T13:37:51.101Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T13:38:29.694Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T13:49:05.293Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-16T13:51:33.560Z"
   },
   {
    "duration": 346,
    "start_time": "2023-02-16T13:51:43.281Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-16T13:52:05.336Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T13:52:48.169Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-16T13:53:55.403Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-16T13:58:38.396Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-16T14:02:44.793Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T14:02:47.447Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T14:02:50.040Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-16T14:06:32.543Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-16T14:06:48.934Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T14:07:13.950Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-16T14:08:23.910Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-16T14:08:31.702Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T14:08:41.759Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T14:09:19.896Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-16T14:10:20.447Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-16T14:10:26.585Z"
   },
   {
    "duration": 57,
    "start_time": "2023-02-16T14:10:30.707Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T14:13:15.460Z"
   },
   {
    "duration": 62,
    "start_time": "2023-02-16T14:14:39.703Z"
   },
   {
    "duration": 32,
    "start_time": "2023-02-16T14:15:03.795Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-16T14:15:32.563Z"
   },
   {
    "duration": 48,
    "start_time": "2023-02-16T14:15:50.321Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-16T14:15:58.675Z"
   },
   {
    "duration": 1489,
    "start_time": "2023-02-16T14:19:17.658Z"
   },
   {
    "duration": 2310,
    "start_time": "2023-02-16T14:19:30.907Z"
   },
   {
    "duration": 2164,
    "start_time": "2023-02-16T14:20:08.716Z"
   },
   {
    "duration": 2000,
    "start_time": "2023-02-16T14:20:21.992Z"
   },
   {
    "duration": 625,
    "start_time": "2023-02-16T14:20:34.308Z"
   },
   {
    "duration": 4375,
    "start_time": "2023-02-16T14:21:17.192Z"
   },
   {
    "duration": 2788,
    "start_time": "2023-02-16T14:21:29.476Z"
   },
   {
    "duration": 1715,
    "start_time": "2023-02-16T14:21:41.385Z"
   },
   {
    "duration": 612,
    "start_time": "2023-02-16T14:21:57.158Z"
   },
   {
    "duration": 761,
    "start_time": "2023-02-16T14:22:56.640Z"
   },
   {
    "duration": 725,
    "start_time": "2023-02-16T14:23:01.763Z"
   },
   {
    "duration": 561,
    "start_time": "2023-02-16T14:23:10.640Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-16T14:24:28.260Z"
   },
   {
    "duration": 653,
    "start_time": "2023-02-16T14:24:41.990Z"
   },
   {
    "duration": 22,
    "start_time": "2023-02-16T14:29:11.866Z"
   },
   {
    "duration": 81,
    "start_time": "2023-02-16T14:31:01.795Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T14:35:15.462Z"
   },
   {
    "duration": 2521,
    "start_time": "2023-02-16T14:35:28.648Z"
   },
   {
    "duration": 1119,
    "start_time": "2023-02-16T14:35:31.171Z"
   },
   {
    "duration": 1107,
    "start_time": "2023-02-16T14:35:32.292Z"
   },
   {
    "duration": 2450,
    "start_time": "2023-02-16T14:35:33.401Z"
   },
   {
    "duration": 997,
    "start_time": "2023-02-16T14:35:35.852Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-16T14:35:36.866Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-16T14:35:36.928Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-16T14:35:36.990Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T14:35:37.004Z"
   },
   {
    "duration": 14853,
    "start_time": "2023-02-16T14:35:37.034Z"
   },
   {
    "duration": 14575,
    "start_time": "2023-02-16T14:35:51.888Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-16T14:36:06.548Z"
   },
   {
    "duration": 57069,
    "start_time": "2023-02-16T14:36:06.574Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T14:37:03.644Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T14:37:03.645Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T14:37:03.646Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T14:37:03.646Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T14:37:03.649Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T14:37:03.651Z"
   },
   {
    "duration": 23361,
    "start_time": "2023-02-16T14:38:03.047Z"
   },
   {
    "duration": 49511,
    "start_time": "2023-02-16T14:38:29.295Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-16T14:39:43.023Z"
   },
   {
    "duration": 17108,
    "start_time": "2023-02-16T14:39:52.089Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T14:40:26.088Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-16T14:40:39.532Z"
   },
   {
    "duration": 31086,
    "start_time": "2023-02-16T16:11:45.336Z"
   },
   {
    "duration": 1405,
    "start_time": "2023-02-16T16:12:16.425Z"
   },
   {
    "duration": 1158,
    "start_time": "2023-02-16T16:12:17.831Z"
   },
   {
    "duration": 2176,
    "start_time": "2023-02-16T16:12:18.991Z"
   },
   {
    "duration": 3547,
    "start_time": "2023-02-16T16:12:21.169Z"
   },
   {
    "duration": 51,
    "start_time": "2023-02-16T16:12:24.718Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-16T16:12:24.770Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-16T16:12:24.782Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T16:12:24.800Z"
   },
   {
    "duration": 12604,
    "start_time": "2023-02-16T16:12:24.805Z"
   },
   {
    "duration": 12653,
    "start_time": "2023-02-16T16:12:37.411Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-16T16:12:50.066Z"
   },
   {
    "duration": 388,
    "start_time": "2023-02-16T16:12:50.071Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-16T16:12:50.461Z"
   },
   {
    "duration": 219,
    "start_time": "2023-02-16T16:12:50.492Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T16:12:50.713Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T16:12:50.714Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T16:12:50.716Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T16:12:50.718Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T16:12:50.719Z"
   },
   {
    "duration": 19008,
    "start_time": "2023-02-16T16:13:54.249Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T16:35:38.906Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T16:36:03.224Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-16T16:36:03.931Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T16:36:06.249Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T16:37:40.487Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T16:37:42.304Z"
   },
   {
    "duration": 131,
    "start_time": "2023-02-16T16:38:28.923Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-16T16:38:45.731Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T16:39:24.862Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-16T16:39:26.292Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T16:40:46.589Z"
   },
   {
    "duration": 1642,
    "start_time": "2023-02-16T16:40:49.000Z"
   },
   {
    "duration": 26728,
    "start_time": "2023-02-17T08:03:41.847Z"
   },
   {
    "duration": 1797,
    "start_time": "2023-02-17T08:04:08.578Z"
   },
   {
    "duration": 1092,
    "start_time": "2023-02-17T08:04:10.377Z"
   },
   {
    "duration": 3454,
    "start_time": "2023-02-17T08:04:11.472Z"
   },
   {
    "duration": 3047,
    "start_time": "2023-02-17T08:04:14.932Z"
   },
   {
    "duration": 51,
    "start_time": "2023-02-17T08:04:17.981Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-17T08:04:18.035Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-17T08:04:18.056Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-17T08:04:18.074Z"
   },
   {
    "duration": 13577,
    "start_time": "2023-02-17T08:04:18.080Z"
   },
   {
    "duration": 14350,
    "start_time": "2023-02-17T08:04:31.659Z"
   },
   {
    "duration": 92,
    "start_time": "2023-02-17T08:04:46.010Z"
   },
   {
    "duration": 423,
    "start_time": "2023-02-17T08:04:46.105Z"
   },
   {
    "duration": 1457,
    "start_time": "2023-02-17T08:04:46.536Z"
   },
   {
    "duration": 16203,
    "start_time": "2023-02-17T08:04:47.995Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-17T08:05:04.200Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-17T08:05:04.206Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-17T08:05:04.214Z"
   },
   {
    "duration": 280,
    "start_time": "2023-02-17T08:05:04.225Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-17T08:05:04.508Z"
   },
   {
    "duration": 7818,
    "start_time": "2023-02-17T08:45:30.590Z"
   },
   {
    "duration": 56,
    "start_time": "2023-02-17T08:45:51.582Z"
   },
   {
    "duration": 6241,
    "start_time": "2023-02-17T08:45:59.873Z"
   },
   {
    "duration": 10620,
    "start_time": "2023-02-17T08:58:50.971Z"
   },
   {
    "duration": 10067,
    "start_time": "2023-02-17T08:59:45.943Z"
   },
   {
    "duration": 73,
    "start_time": "2023-02-17T08:59:59.272Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-17T09:00:19.487Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-17T09:00:31.899Z"
   },
   {
    "duration": 8955,
    "start_time": "2023-02-17T09:03:50.983Z"
   },
   {
    "duration": 28027,
    "start_time": "2023-02-17T09:32:30.750Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
